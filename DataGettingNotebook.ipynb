{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to retrieve html code from webpages\n",
    "import requests\n",
    "\n",
    "# Used to parse webpages\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Import pandas for dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# Used for input validation\n",
    "import re\n",
    "\n",
    "# Used to correctly format dates\n",
    "from datetime import datetime\n",
    "\n",
    "# Import sqlite3 so we can use sqlite databases\n",
    "import sqlite3\n",
    "\n",
    "# Import other python files (help with db management)\n",
    "from python_files.Queries import Queries\n",
    "from python_files.UseDB import UseDB\n",
    "\n",
    "# Helps with iterating through differing data structures\n",
    "import itertools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Functions To Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date(time_string):\n",
    "    # Define the format of the input and output string\n",
    "    input_format = '%I:%M %p, %B %d, %Y'\n",
    "    output_format = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "    # Convert the input string to a datetime object\n",
    "    datetime_obj = datetime.strptime(time_string, input_format)\n",
    "\n",
    "    # Convert the datetime object to a string in the output format\n",
    "    output_date = datetime_obj.strftime(output_format)\n",
    "    \n",
    "    return output_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_game_id(teams, date, game_num):\n",
    "    \n",
    "    game_id = date.split()[0]\n",
    "    for team in teams:\n",
    "        first_letters = [word[0] for word in team.split()]\n",
    "        result = ''.join(first_letters)\n",
    "        \n",
    "        game_id += \"-\"\n",
    "        game_id += result\n",
    "    \n",
    "    game_id = game_id + \"-\" + game_num\n",
    "        \n",
    "    return game_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_umps(ump_string):\n",
    "    \n",
    "    # Get the umps name out of the string\n",
    "    word_list = ump_string.split('-')\n",
    "    ump_name = word_list[1].strip()\n",
    "    \n",
    "    return ump_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_id(html):\n",
    "    \n",
    "    # See if there is a table for stats on the webpage\n",
    "    elements = html.find_all('div', class_='Boxscore__Team')\n",
    "    \n",
    "    # The game was not rained out if there are elements to retrieve\n",
    "    if elements:\n",
    "        \n",
    "        # Get the data and format it into something we can use\n",
    "        formatted_date = format_date(html.find('div', {'class': 'n8 GameInfo__Meta'}).find('span').text)\n",
    "        teams = html.find_all('h2', {'class': 'ScoreCell__TeamName ScoreCell__TeamName--displayName truncate db'})\n",
    "        \n",
    "        try:\n",
    "            # If there is a value returned: this game was part of a double header\n",
    "            game_num = html.find('div', {'class': 'ScoreCell__GameNote di'}).text\n",
    "            \n",
    "            # Set the game number - to be used in the game id\n",
    "            if \"1\" in game_num:\n",
    "                game_num = \"1\"\n",
    "            elif \"2\" in game_num:\n",
    "                game_num = \"2\"\n",
    "            else:\n",
    "                # For the edge cases (MLB Opening Day, etc.)\n",
    "                game_num = \"1\"\n",
    "        except:\n",
    "            # The game was not part of a double header, just put game_num = 1\n",
    "            game_num = \"1\"\n",
    "        \n",
    "        # Add the variables to a dictionary\n",
    "        game_id = make_game_id([teams[0].text, teams[1].text], formatted_date, game_num)\n",
    "        \n",
    "        return game_id\n",
    "    \n",
    "    # The game on this day was postponed, return an empty list\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hitter_statistics(html, team):\n",
    "    \"\"\"\n",
    "    Pass in html and receive the batter statistics from an ESPN web page.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Valuable variables and lists\n",
    "    batting_categories = ['ID', 'NAME', 'AB', 'R', 'H', 'RBI', 'HR', 'BB', 'K', 'AVG', 'OBP', 'SLG','STRT']\n",
    "    \n",
    "    # Correctly gets all of the player's names\n",
    "    elements = html.find_all('div', class_='Boxscore__Team')\n",
    "    \n",
    "    # The game was not rained out if there are elements to retrieve\n",
    "    if elements:\n",
    "        \n",
    "        # Lists to hold important information\n",
    "        non_starters = []\n",
    "        player_names = []\n",
    "        player_stats = []\n",
    "        \n",
    "        # Decides whether to get the home or away team's stats\n",
    "        team = team.lower()\n",
    "        if team == \"away\": \n",
    "            i = 0  # Will retrieve away team's stats\n",
    "        elif team == 'home': \n",
    "            i = 1  # Will retrive home team's stats\n",
    "            \n",
    "        # Get the game_id\n",
    "        id = get_game_id(html)\n",
    "        \n",
    "        # Get all of the batters that did not start the game\n",
    "        for player_html in elements[i].find_all('div', {'class': 'Boxscore__Athlete pl4'}):\n",
    "            for player_name in player_html.find('a'):\n",
    "                non_starters.append(player_name)\n",
    "                \n",
    "        # Get all of the player names\n",
    "        for player in elements[i].find_all('a', {'class': 'Boxscore__Athlete_Name'}):\n",
    "            name = player.text\n",
    "            player_names.append(name)\n",
    "\n",
    "        # Get all of the player numerical stats\n",
    "        number_stat_element = elements[i].find('div', {'class': 'Table__Scroller'})\n",
    "        for row in number_stat_element.find_all('tr'):\n",
    "            one_row_stats = [td.text.strip() for td in row.find_all('td')]\n",
    "            player_stats.append(one_row_stats)\n",
    "\n",
    "        # Get rid of the empty list in the first position of the list\n",
    "        # Get rid of the last element which includes game total numbers that we dont want\n",
    "        player_stats = player_stats[1:len(player_stats)-1]\n",
    "\n",
    "        # Format the data into useful dictionaries\n",
    "        all_things = []\n",
    "        for index, row in enumerate(player_stats):\n",
    "            # Add an element for whether the batter started the game or not\n",
    "            if player_names[index] in non_starters:  # Batter did not start the game\n",
    "                row.append(0)\n",
    "            else:\n",
    "                row.append(1)  # Batter did start the game\n",
    "                \n",
    "            # Add the player name to the start of the list\n",
    "            row.insert(0, player_names[index])\n",
    "            \n",
    "            # Add game id to the start of the list\n",
    "            row.insert(0, id)\n",
    "\n",
    "            # Zip the stat category with the statistic\n",
    "            all_things.append(dict(zip(batting_categories, row)))\n",
    "\n",
    "        # Get rid of ERA values which are not needed\n",
    "        for index in range(len(all_things)):\n",
    "            del all_things[index]['AVG']\n",
    "            del all_things[index]['OBP']\n",
    "            del all_things[index]['SLG']\n",
    "            \n",
    "        return all_things\n",
    "    \n",
    "    # The game on this day was postponed, return an empty list\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pitcher_statistics(html, team):\n",
    "    \"\"\"\n",
    "    Pass in html and receive the pitcher statistics from an ESPN web page.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Valuable variables and lists\n",
    "    pitching_categories = ['ID', 'NAME', 'IP', 'H', 'R', 'ER', 'BB', 'K', 'HR', 'ERA', \"STRKS\", \"BALLS\", 'STRT']\n",
    "    \n",
    "    # Correctly gets all of the player's names\n",
    "    elements = html.find_all('div', class_='Boxscore__Team')\n",
    "    \n",
    "    # The game was not rained out if there are elements to retrieve\n",
    "    if elements:\n",
    "        \n",
    "        # Lists to hold important information\n",
    "        non_starters = []\n",
    "        player_names = []\n",
    "        player_stats = []\n",
    "        \n",
    "        # Decides whether to get the home or away team's stats\n",
    "        team = team.lower()\n",
    "        if team == \"away\": \n",
    "            i = 2  # Will retrieve away team's stats\n",
    "        elif team == 'home': \n",
    "            i = 3  # Will retrive home team's stats\n",
    "            \n",
    "        # Get the game_id\n",
    "        id = get_game_id(html)\n",
    "        \n",
    "        # Get all of the batters that did not start the game\n",
    "        for player_html in elements[i].find_all('div', {'class': 'Boxscore__Athlete pl4'}):\n",
    "            for player_name in player_html.find('a'):\n",
    "                non_starters.append(player_name)\n",
    "                \n",
    "        # Get all of the player names\n",
    "        for player in elements[i].find_all('a', {'class': 'Boxscore__Athlete_Name'}):\n",
    "            name = player.text\n",
    "            player_names.append(name)\n",
    "\n",
    "        # Get all of the player numerical stats\n",
    "        number_stat_element = elements[i].find('div', {'class': 'Table__Scroller'})\n",
    "        for row in number_stat_element.find_all('tr'):\n",
    "            one_row_stats = [td.text.strip() for td in row.find_all('td')]\n",
    "            player_stats.append(one_row_stats)\n",
    "\n",
    "        # Get rid of the empty list in the first position of the list\n",
    "        # Get rid of the last element which includes game total numbers that we dont want\n",
    "        player_stats = player_stats[1:len(player_stats)-1]\n",
    "        \n",
    "        # Go through each player and get ball and strike totals\n",
    "        for index in range(len(player_names)):\n",
    "            \n",
    "            # Get ball and strike totals\n",
    "            ball_and_strikes = player_stats[index][7].split(\"-\")\n",
    "            total_pitches = int(ball_and_strikes[0])\n",
    "            strikes = int(ball_and_strikes[1])\n",
    "            balls = total_pitches - strikes\n",
    "            \n",
    "            # Delete the string ball and stike value and add the only balls and only strike values to the list\n",
    "            del player_stats[index][7]\n",
    "            player_stats[index].append(strikes)\n",
    "            player_stats[index].append(balls)\n",
    "            \n",
    "            # Add the player name to the start of the list\n",
    "            player_stats[index].insert(0, player_names[index])\n",
    "            \n",
    "            # Add game id to the start of the list\n",
    "            player_stats[index].insert(0, id)\n",
    "        \n",
    "        # Format the data into useful dictionaries\n",
    "        all_things = []\n",
    "        for index, row in enumerate(player_stats):    \n",
    "            # Add an element for whther the pitcher started the game or not\n",
    "            if player_names[index] == player_names[0]:\n",
    "                row.append(1)  # Starting Pitcher\n",
    "            else:\n",
    "                row.append(0)  # Relief Pitcher\n",
    "            all_things.append(dict(zip(pitching_categories, row)))\n",
    "        \n",
    "        # Get rid of ERA values which are not needed\n",
    "        for index in range(len(all_things)):\n",
    "            del all_things[index]['ERA']\n",
    "            \n",
    "        return all_things\n",
    "    \n",
    "    # The game on this day was postponed, return an empty list\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hitter_gamelog_data(url: str):\n",
    "\n",
    "    # Get the html code from the webpage\n",
    "    response = requests.get(url=url)\n",
    "\n",
    "    # Make sure the webpage was returned\n",
    "    if response.status_code == 200:\n",
    "        \n",
    "        # Parse the HTML content of the response\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Get the away and home team's hitting statistics\n",
    "        away_hitters = get_hitter_statistics(soup, \"away\")\n",
    "        home_hitters = get_hitter_statistics(soup, \"home\")\n",
    "        \n",
    "        # Make the dictionaries into pandas DataFrames\n",
    "        away_hitters = pd.DataFrame(away_hitters)\n",
    "        home_hitters = pd.DataFrame(home_hitters)\n",
    "            \n",
    "    else:\n",
    "        # The request could not be made\n",
    "        print(f\"Error fetching {url}: {response.status_code}\")\n",
    "        \n",
    "    return away_hitters, home_hitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pitcher_gamelog_data(url: str):\n",
    "\n",
    "    # Get the html code from the webpage\n",
    "    response = requests.get(url=url)\n",
    "\n",
    "    # Make sure the webpage was returned\n",
    "    if response.status_code == 200:\n",
    "        \n",
    "        # Parse the HTML content of the response\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Get the away and home team's hitting statistics\n",
    "        away_pitchers = get_pitcher_statistics(soup, \"away\")\n",
    "        home_pitchers = get_pitcher_statistics(soup, \"home\")\n",
    "        \n",
    "        # Make the dictionaries into pandas DataFrames\n",
    "        away_pitchers = pd.DataFrame(away_pitchers)\n",
    "        home_pitchers = pd.DataFrame(home_pitchers)\n",
    "            \n",
    "    else:\n",
    "        # The request could not be made\n",
    "        print(f\"Error fetching {url}: {response.status_code}\")\n",
    "        \n",
    "    return away_pitchers, home_pitchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inning_data(url):\n",
    "    # Get the html code from the webpage\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Response was successful if 200\n",
    "    if response.status_code == 200:\n",
    "        \n",
    "        # Parse the HTML content of the response\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # See if there is a table for stats on the webpage\n",
    "        elements = soup.find_all('div', class_='Boxscore__Team')\n",
    "        \n",
    "        # The game was not rained out if there are elements to retrieve\n",
    "        if elements:\n",
    "            \n",
    "            # Get the game id\n",
    "            id = get_game_id(soup)\n",
    "            \n",
    "            # Get the teams\n",
    "            teams = soup.find_all('h2', {'class': 'ScoreCell__TeamName ScoreCell__TeamName--displayName truncate db'})\n",
    "            \n",
    "            # Needed variables\n",
    "            pattern = r'\\d{2,}'  # Regular expression pattern to match numbers larger than 9\n",
    "            extra_innings = False\n",
    "\n",
    "            # Get the html content of the by inning scores\n",
    "            table_rows = soup.find_all('tbody')[1].find_all('tr')\n",
    "            table_head = soup.find_all('thead')[1].find_all('tr')\n",
    "            \n",
    "            # Get the inning data\n",
    "            headers = [td.text for td in table_head[0].find_all('th')]\n",
    "            away_team = [td.text for td in table_rows[0].find_all('td')]\n",
    "            home_team = [td.text for td in table_rows[1].find_all('td')]\n",
    "\n",
    "            # Filter out strings that match the pattern\n",
    "            updated_headers = [s for s in headers if not re.search(pattern, s)]\n",
    "            \n",
    "            # For any half innings that were not played, update the list to have a\n",
    "            # `-1` value for those half innings instead of a `-`\n",
    "            updated_away_team = [int(s) if s != '-' else -1 for s in away_team]\n",
    "            updated_home_team = [int(s) if s != '-' else -1 for s in home_team]\n",
    "            \n",
    "            # If the game went to extra innings, get rid of all data from the extra innings\n",
    "            # and turn the extra_inning boolean variable to true\n",
    "            if len(updated_away_team) > 12:\n",
    "                updated_away_team = updated_away_team[:9] + updated_away_team[-3:]\n",
    "                updated_home_team = updated_home_team[:9] + updated_home_team[-3:]\n",
    "                extra_innings = True\n",
    "            \n",
    "            # Create instances of the dictionaries\n",
    "            away_dict = {}\n",
    "            home_dict = {}\n",
    "            \n",
    "            # Add the game id to the dictionaries\n",
    "            away_dict['ID'] = id\n",
    "            home_dict['ID'] = id\n",
    "            \n",
    "            # Add the away or home team thing to the row\n",
    "            away_dict['TEAM'] = \"away\"\n",
    "            home_dict['TEAM'] = \"home\"\n",
    "            \n",
    "            # Add the team names to the dictionary's\n",
    "            away_dict['NAME'] = teams[0].text\n",
    "            home_dict['NAME'] = teams[1].text\n",
    "            \n",
    "            # Add the inning data to the dictionaries\n",
    "            for i in range(len(updated_headers)):\n",
    "                away_dict[f'{updated_headers[i]}'] = updated_away_team[i]\n",
    "                home_dict[f'{updated_headers[i]}'] = updated_home_team[i]\n",
    "            \n",
    "            # Add a value key pair to indicate whether the game went to extra innings or not\n",
    "            if extra_innings:\n",
    "                away_dict['EI'] = 1\n",
    "                home_dict['EI'] = 1\n",
    "            else:\n",
    "                away_dict['EI'] = 0\n",
    "                home_dict['EI'] = 0\n",
    "            \n",
    "            return away_dict, home_dict\n",
    "        \n",
    "        # The game on this day was postponed, return an empty list\n",
    "        else:\n",
    "            return ({}, {})\n",
    "        \n",
    "    else:\n",
    "        # The request could not be made\n",
    "        print(f\"Error fetching {url}: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_other_data(url):\n",
    "\n",
    "    # Get the html code from the webpage\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        \n",
    "        # Parse the HTML content of the response\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # See if there is a table for stats on the webpage\n",
    "        elements = soup.find_all('div', class_='Boxscore__Team')\n",
    "        \n",
    "        # The game was not rained out if there are elements to retrieve\n",
    "        if elements:\n",
    "        \n",
    "            # Hold the data\n",
    "            data_dict = {}\n",
    "            \n",
    "            # Get the data\n",
    "            location = soup.find('span', {'class': 'Location__Text'}).text.strip()\n",
    "            formatted_date = format_date(soup.find('div', {'class': 'n8 GameInfo__Meta'}).find('span').text)\n",
    "            stadium = soup.find('div', {'class', 'n6 clr-gray-03 GameInfo__Location__Name'}).text.strip()\n",
    "            betting_line = soup.find('div', {'class': 'n8 GameInfo__BettingItem flex-expand line'}).text\n",
    "            game_time_length = soup.find('div', {'class': 'GameInfo__List list inline-flex flex-wrap'}).text.replace(\"Game Time:\", \"\")\n",
    "            teams = soup.find_all('h2', {'class': 'ScoreCell__TeamName ScoreCell__TeamName--displayName truncate db'})\n",
    "            umpire_list = soup.find('ul', class_='GameInfo__List list inline-flex flex-wrap')\n",
    "            umpires = umpire_list.find_all('li', class_='GameInfo__List__Item')\n",
    "            \n",
    "            # Format betting line\n",
    "            seperated_bl = betting_line.replace(\"Line:\", \"\").strip().split()\n",
    "            \n",
    "            try:\n",
    "                # If there is a value returned: this game was part of a double header\n",
    "                game_num = soup.find('div', {'class': 'ScoreCell__GameNote di'}).text\n",
    "                \n",
    "                # Set the game number - to be used in the game id\n",
    "                if \"1\" in game_num:\n",
    "                    game_num = \"1\"\n",
    "                elif \"2\" in game_num:\n",
    "                    game_num = \"2\"\n",
    "                else:\n",
    "                    # For the edge cases (MLB Opening Day, etc.)\n",
    "                    game_num = \"1\"\n",
    "            except:\n",
    "                # The game was not part of a double header, just put game_num = 1\n",
    "                game_num = \"1\"\n",
    "            \n",
    "            # Add the variables to a dictionary\n",
    "            data_dict['GameID'] = make_game_id([teams[0].text, teams[1].text], formatted_date, game_num)\n",
    "            data_dict['Location'] = location\n",
    "            data_dict['Date'] = formatted_date\n",
    "            data_dict['Stadium'] = stadium\n",
    "            data_dict['Fav. Team'] = seperated_bl[0]\n",
    "            data_dict['Bet Line'] = seperated_bl[1]\n",
    "            data_dict['Game Length'] = game_time_length\n",
    "            data_dict['Away Team'] = teams[0].text\n",
    "            data_dict['Home Team'] = teams[1].text\n",
    "            data_dict['Home Plate'] = format_umps(umpires[0].text)\n",
    "            data_dict['1st base'] = format_umps(umpires[1].text)\n",
    "            data_dict['2nd base'] = format_umps(umpires[2].text)\n",
    "            data_dict['3rd base'] = format_umps(umpires[3].text)\n",
    "\n",
    "            return data_dict\n",
    "        \n",
    "        # The game on this day was postponed, return an empty list\n",
    "        else:\n",
    "            return []\n",
    "        \n",
    "    else:\n",
    "        # The request could not be made\n",
    "        print(f\"Error fetching {url}: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictive_stats(url: str):\n",
    "    \n",
    "    # Get the html code from the webpage\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        \n",
    "        # Parse the HTML content of the response\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # See if there is a table for stats on the webpage\n",
    "        elements = soup.find_all('div', class_='Boxscore__Team')\n",
    "        \n",
    "        # The game was not rained out if there are elements to retrieve\n",
    "        if elements:\n",
    "        \n",
    "            # Hold the data\n",
    "            data_dict = {}\n",
    "            \n",
    "            # Get the data\n",
    "            location = soup.find('span', {'class': 'Location__Text'}).text.strip()\n",
    "            formatted_date = format_date(soup.find('div', {'class': 'n8 GameInfo__Meta'}).find('span').text)\n",
    "            stadium = soup.find('div', {'class', 'n6 clr-gray-03 GameInfo__Location__Name'}).text.strip()\n",
    "            betting_line = soup.find('div', {'class': 'n8 GameInfo__BettingItem flex-expand line'}).text\n",
    "            teams = soup.find_all('h2', {'class': 'ScoreCell__TeamName ScoreCell__TeamName--displayName truncate db'})\n",
    "            umpire_list = soup.find('ul', class_='GameInfo__List list inline-flex flex-wrap')\n",
    "            umpires = umpire_list.find_all('li', class_='GameInfo__List__Item')\n",
    "            \n",
    "            # Get the away and home team's hitting statistics\n",
    "            away_pitchers = get_pitcher_statistics(soup, \"away\")\n",
    "            home_pitchers = get_pitcher_statistics(soup, \"home\")\n",
    "            \n",
    "            try:\n",
    "                # If there is a value returned: this game was part of a double header\n",
    "                game_num = soup.find('div', {'class': 'ScoreCell__GameNote di'}).text\n",
    "                \n",
    "                # Set the game number - to be used in the game id\n",
    "                if \"1\" in game_num:\n",
    "                    game_num = \"1\"\n",
    "                elif \"2\" in game_num:\n",
    "                    game_num = \"2\"\n",
    "                else:\n",
    "                    # For the edge cases (MLB Opening Day, etc.)\n",
    "                    game_num = \"1\"\n",
    "            except:\n",
    "                # The game was not part of a double header, just put game_num = 1\n",
    "                game_num = \"1\"\n",
    "            \n",
    "            # Add the variables to a dictionary\n",
    "            data_dict['GameID'] = make_game_id([teams[0].text, teams[1].text], formatted_date, game_num)\n",
    "            data_dict['Date'] = formatted_date\n",
    "            data_dict['Location'] = location\n",
    "            data_dict['Stadium'] = stadium\n",
    "            data_dict['Away Team'] = teams[0].text\n",
    "            data_dict['Home Team'] = teams[1].text\n",
    "            data_dict['AWAY_P'] = away_pitchers[0]['NAME']\n",
    "            data_dict['HOME_P'] = home_pitchers[0]['NAME']\n",
    "            data_dict['Home Plate'] = format_umps(umpires[0].text)\n",
    "            data_dict['1st base'] = format_umps(umpires[1].text)\n",
    "            data_dict['2nd base'] = format_umps(umpires[2].text)\n",
    "            \n",
    "            try:\n",
    "                data_dict['3rd base'] = format_umps(umpires[3].text)\n",
    "            except IndexError:\n",
    "                data_dict['3rd base'] = \"NONE\"\n",
    "        \n",
    "            # Get the html content of the by inning scores and get the inning data\n",
    "            table_rows = soup.find_all('tbody')[1].find_all('tr')\n",
    "            away_team = [td.text for td in table_rows[0].find_all('td')]\n",
    "            home_team = [td.text for td in table_rows[1].find_all('td')]\n",
    "            \n",
    "            # Get the total runs scored in the first inning\n",
    "            first_inning_rs = int(away_team[0]) + int(home_team[0])\n",
    "            \n",
    "            # If there was no runs scores, set the nrfi value to be true\n",
    "            nrfi = 1 if first_inning_rs == 0 else 0\n",
    "            data_dict['NRFI'] = nrfi\n",
    "        \n",
    "            return data_dict\n",
    "        \n",
    "        # The game on this day was postponed, return an empty list\n",
    "        else:\n",
    "            return {}\n",
    "        \n",
    "    else:\n",
    "        # The request could not be made\n",
    "        print(f\"Error fetching {url}: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
